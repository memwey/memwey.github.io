[{"content":"本文介绍在一台 Ubuntu 22.04 的服务器下搭建 WireGuard 服务器端, 附带有客户端的一些配置.\n安装 WireGuard 已经集成在 5.6 及以上版本的 Linux Kernel 中, Ubuntu 22.04 系统下直接安装即可\n1 2 sudo apt update sudo apt install wireguard 生成密钥对 1 2 3 cd /etc/wireguard wg genkey | tee s_private.key | wg pubkey \u0026gt; s_public.key wg genkey | tee c_private.key | wg pubkey \u0026gt; c_public.key 此时会在目录下生成四个文件, 具体说明如下\n文件名 文件说明 s_private.key 服务器端私钥 s_public.key 服务器端公钥 c_private.key 客户端私钥 c_public.key 客户端公钥 配置 WireGuard 服务器端 具体需要各端准备的变量有以下这些\n服务器端: 公网 IP, 内网 IP, 公网端口, 公钥, 私钥, 网络接口 客户端: 内网 IP, 私钥, 公钥 整理为如下表格\n服务器端 客户端 公网IP 233.233.233.233 内网IP 192.168.1.1 192.168.1.2 端口配置 udp/6666 私钥文件 s_private.key c_private.key 公钥文件 s_public.key c_public.key 网络接口 eth0 编写配置文件 文件位置为 /etc/wireguard/wg0.conf\n1 2 3 4 5 6 7 8 9 10 11 [Interface] Address = 192.168.1.1 DNS = 223.6.6.6 ListenPort = 6666 PrivateKey = s_private.key PostUp = iptables -A FORWARD -i wg0 -j ACCEPT; iptables -A FORWARD -o wg0 -j ACCEPT; iptables -t nat -A POSTROUTING -o eth0 -j MASQUERADE PostDown = iptables -D FORWARD -i wg0 -j ACCEPT; iptables -D FORWARD -o wg0 -j ACCEPT; iptables -t nat -D POSTROUTING -o eth0 -j MASQUERADE [Peer] PublicKey = c_public.key AllowedIPs = 192.168.1.2 其中 Interface 可以大致理解为本机的配置, 而 Peer 是面向外部的配置. 有一些参数需要按照实际情况调整, 密钥需要替换为实际的字符串\n其他服务器配置 在服务器端启动 IP 转发\n1 sysctl net.ipv4.ip_forward=1 另外, 可能需要云主机上配置开放对应的 UDP 端口\n启动与停止 配置完成后, 可以使用如下命令, 分别是启动, 查看状态, 停止\n1 2 3 wg-quick up wg0 wg show wg0 wg-quick down wg0 WireGuard 客户端配置 编写配置文件 文件命名为 client.conf\n1 2 3 4 5 6 7 8 9 10 [Interface] PrivateKey = c_private.key Address = 192.168.1.2 DNS = 223.6.6.6 [Peer] PublicKey = s_public.key Endpoint = 233.233.233.233:6666 AllowedIPs = 0.0.0.0/0 PersistentKeepalive = 25 也是要根据实际情况做相应的修改, 密钥替换为实际的字符串\n其他客户端配置 可以使用如下命令在命令行生成二维码, 方便手机扫描\n1 qrencode -t ansiutf8 \u0026lt; client.conf ","date":"2022-11-29T19:00:24+09:00","permalink":"https://memwey.github.io/p/%E6%90%AD%E5%BB%BA-wireguard-%E7%BD%91%E7%BB%9C/","title":"搭建 WireGuard 网络"},{"content":"因为 Prometheus 在应用中一共只有四种 metric 类型, 只要根据需要监测的目标选择了 metrics 类型, 后续的告警以及可视化配置就有固定的套路了.\nCounter Counter 用来监控单调递增的量, 当发生重置时 Prometheus 会自动处理归零的数据. 这是一个非常基本的类型, 一个系统中很多数据都可以通过此类型进行计数, 比如系统接受的请求数, 系统发生的错误数, 再比如对第三方接口的调用数, 第三方接口返回的错误数.\n业务代码如下\n1 2 3 4 5 6 7 from prometheus_client import Counter c = Counter( \u0026#39;web_request_total\u0026#39;, \u0026#39;web request total counter\u0026#39;, [\u0026#39;method\u0026#39;, \u0026#39;endpoint\u0026#39;, \u0026#39;status_code\u0026#39;] ) c.labels(\u0026#39;get\u0026#39;, \u0026#39;/\u0026#39;, \u0026#39;200\u0026#39;).inc() c.labels(\u0026#39;post\u0026#39;, \u0026#39;/submit\u0026#39;, \u0026#39;500\u0026#39;).inc() 此时在业务暴露出来的端点上会有这样两条记录\n1 2 web_request_total{method=\u0026#34;/submit\u0026#34;,method=\u0026#34;post\u0026#34;,status_code=\u0026#34;500\u0026#34;} 1 web_request_total{method=\u0026#34;/\u0026#34;,method=\u0026#34;get\u0026#34;,status_code=\u0026#34;200\u0026#34;} 1 对于 Counter 我们一般看增长量和增长速率\nsum(increase(web_request_total[5m])) 五分钟内总请求数 sum(increase(web_request_total{status_code!~\u0026quot;^2..\u0026quot;}[1m])) 一分钟内状态码不为2xx的总请求数 sum(irate(web_request_total[1m])) 一分钟内总请求数增长率 告警则一般设置为\n一分钟内总请求中有有超过 5% 的 5xx 错误, 持续一分钟 1 2 expr: sum(rate(web_request_total{status_code=~\u0026#34;^5..\u0026#34;}[1m])) / sum(rate(web_request_total[1m])) * 100 \u0026gt; 5 for: 1m 一分钟内 5xx 错误的请求增长率高于 100%, 持续一分钟 1 2 expr: sum(irate(web_request_total{status_code=~\u0026#34;^5..\u0026#34;}[1m])) \u0026gt; 100 for: 1m Gauge Gauge 是一个瞬时量, 在时间上来看是可增可减的, 用以记录系统在某个时刻的当前状态, 比如当前实例线程数, 当前系统负载, 某个队列的长度, 某个队列的消费延时等.\n业务代码如下\n1 2 3 4 5 6 7 8 9 10 11 12 13 from prometheus_client import Gauge g1 = Gauge( \u0026#39;kafka_consumer_lag_seconds\u0026#39;, \u0026#39;kafka consume lag in second\u0026#39;, [\u0026#39;topic\u0026#39;, \u0026#39;consumer_group\u0026#39;] ) g1.labels(\u0026#39;k-test\u0026#39;, \u0026#39;grp1\u0026#39;).set(233) g2 = Gauge( \u0026#39;redis_connection_pool_count\u0026#39;, \u0026#39;redis connection poll count\u0026#39;, [\u0026#39;state\u0026#39;] ) g2.labels(\u0026#39;idle\u0026#39;).set(10) g2.labels(\u0026#39;active\u0026#39;).set(22) g2.labels(\u0026#39;total\u0026#39;).set(32) 此时在业务暴露出来的端点上会有这样的记录\n1 2 3 4 kafka_consumer_lag_seconds{topic=\u0026#34;k-test\u0026#34;,consumer_group=\u0026#34;grp1\u0026#34;} 233 redis_connection_pool_count{state=\u0026#34;idle\u0026#34;} 10 redis_connection_pool_count{state=\u0026#34;active\u0026#34;} 22 redis_connection_pool_count{state=\u0026#34;total\u0026#34;} 32 对于 Gauge 我们一般直接看其值或者其值的百分比\nkafka_consumer_lag_seconds{topic=\u0026quot;k-test\u0026quot;} 查看 k-test 这个 topic 最新的消费延迟\navg_over_time(kafka_consumer_lag_seconds[1m]) 查看应用全部 kafka 队列一分钟的平均消费延时\nmax_over_time(kafka_consumer_lag_seconds[1m]) 查看应用全部 kafka 队列每一分钟内的最大消费延时\nredis_connection_pool_count{state=\u0026quot;active\u0026quot;} / ignoring(state) redis_connection_pool_count{state=\u0026quot;total\u0026quot;} 查看应用 redis 连接池的使用百分比\n告警则一般设置为\n一分钟内队列的平均消费延时大于 10min, 持续一分钟 1 2 expr: avg_over_time(kafka_consumer_lag_seconds[1m]) \u0026gt; 600 for: 1m Redis 连接池平均占用超过 90%, 持续一分钟 1 2 expr: avg_over_time(redis_connection_pool_count{state=\u0026#34;active\u0026#34;}[1m]) / ignoring(state) avg_over_time(redis_connection_pool_count{state=\u0026#34;total\u0026#34;}[1m]) * 100 \u0026gt; 90 for: 1m Histogram 和 Summary Histogram 可以看作是一个复合的 Counter 类型, 它会将数值按区间计数, 常用于记录 P99, P95 类的数据. 可以用来记录比如接口响应耗时情况, 接口返回数据大小情况等.\n1 2 3 4 5 6 7 from prometheus_client import Histogram h = Histogram( \u0026#39;http_request_duration_seconds\u0026#39;, \u0026#39;Api requests response time in seconds\u0026#39;, [\u0026#39;api\u0026#39;, \u0026#39;method\u0026#39;], (0.1, 0.25, 1, 4, 10) ) h.labels(\u0026#39;/products\u0026#39;, \u0026#39;post\u0026#39;).observe(0.0923) h.labels(\u0026#39;/products\u0026#39;, \u0026#39;post\u0026#39;).observe(0.3672) 此时在业务暴露出来的端点上会有这样的记录, 产生了多条数据, 其中 _sum 是值的总和, _count 是值的计数, _bucket 中有一个命名为 le 特殊的 label, 其中的区间值是我们在代码中配置的, 是值在区间内的计数.\n1 2 3 4 5 6 7 8 http_request_duration_seconds_sum{api=\u0026#34;/products\u0026#34;, \u0026#34;method\u0026#34;=\u0026#34;post\u0026#34;} 0.4595 http_request_duration_seconds_count{api=\u0026#34;/products\u0026#34;, \u0026#34;method\u0026#34;=\u0026#34;post\u0026#34;} 2 http_request_duration_seconds_bucket{api=\u0026#34;/products\u0026#34;, \u0026#34;method\u0026#34;=\u0026#34;post\u0026#34;, le=\u0026#34;0.1\u0026#34;} 1 http_request_duration_seconds_bucket{api=\u0026#34;/products\u0026#34;, \u0026#34;method\u0026#34;=\u0026#34;post\u0026#34;, le=\u0026#34;0.25\u0026#34;} 1 http_request_duration_seconds_bucket{api=\u0026#34;/products\u0026#34;, \u0026#34;method\u0026#34;=\u0026#34;post\u0026#34;, le=\u0026#34;1\u0026#34;} 2 http_request_duration_seconds_bucket{api=\u0026#34;/products\u0026#34;, \u0026#34;method\u0026#34;=\u0026#34;post\u0026#34;, le=\u0026#34;4\u0026#34;} 2 http_request_duration_seconds_bucket{api=\u0026#34;/products\u0026#34;, \u0026#34;method\u0026#34;=\u0026#34;post\u0026#34;, le=\u0026#34;10\u0026#34;} 2 http_request_duration_seconds_bucket{api=\u0026#34;/products\u0026#34;, \u0026#34;method\u0026#34;=\u0026#34;post\u0026#34;, le=\u0026#34;+Inf\u0026#34;} 2 对于 Histogram 一般可以求均值或者 P95, P99 之类的值, 也可以做普通的 Counter 使用\nrate(http_request_duration_seconds_sum{api=\u0026quot;/products\u0026quot;, \u0026quot;method\u0026quot;=\u0026quot;post\u0026quot;}[5m]) / rate(http_request_duration_seconds_count{api=\u0026quot;/products\u0026quot;, \u0026quot;method\u0026quot;=\u0026quot;post\u0026quot;}[5m]) 查看 /products 端点上 POST 请求五分钟内的耗时均值 histogram_quantile(0.99, rate(http_request_duration_seconds_bucket{api=\u0026quot;/products\u0026quot;, \u0026quot;method\u0026quot;=\u0026quot;post\u0026quot;}[5m])) 查看 /products 端点上 POST 请求五分钟内的耗时 P99 increase(http_request_duration_seconds_count{api=\u0026quot;/products\u0026quot;, \u0026quot;method\u0026quot;=\u0026quot;post\u0026quot;}[1m]) 查看 /products 端点上 POST 请求一分钟内的请求数 告警则一般设置为\n两分钟内某个接口 P95 大于 10s, 持续两分钟 1 2 expr: histogram_quantile(0.95, sum(rate(http_request_duration_seconds_bucket[2m])) by (api, method)) \u0026gt; 10 for: 2m 一些有用的资料\nawesome-prometheus-alerts How to visualize Prometheus histograms in Grafana ","date":"2022-05-10T16:36:07+08:00","permalink":"https://memwey.github.io/p/prometheus-%E6%89%8B%E6%8A%8A%E6%89%8B/","title":"Prometheus 手把手"},{"content":"基本概念 Prometheus 是一个开源的监控方案, CNCF 的毕业项目, 云原生监控的事实标准. Prometheus 以时间序列数据的形式收集和存储 metrics. Metrics 信息与被称为标签的可选的键值对和记录时间一起保存.\nPrometheus 的主要功能特点有\n由 metric 的名称以及 Key/Value 对标签标识的时间序列数据组成的多维数据模型 灵活的查询语言 PromQL 不依赖分布式存储; 单服务节点自治能力 服务端通过 HTTP 协议拉取获得的时间序列数据 支持通过中间网关推送时间序列数据 通过服务发现或静态配置文件发现监控目标 支持多种类型的图表和仪表盘 Prometheus 以拉取的模式获取获取监控数据, 而不是由业务方向监控服务器推送. 这对于被监控的业务来说, 极大的减少了监控部分在系统中的耦合. 通常, 业务暴露出一个 HTTP 端口以暴露数据, 供 Prometheus server 抓取即可.\nMetric 一般来说, Metric 是数值形式的标量单位, 它是与时间一起被记录的时间序列. 在不同应用中用户期望记录不同的 Metric. Web server 可能要希望请求数和一些指标信息, 数据库可能希望记录活跃连接数和活跃查询数之类的.\n系统架构 主要的 Prometheus server 收集和存储时间序列数据 客户端库 用以监测应用程序代码 push gateway 用以支持短期运行的任务 用以监控 HAProxy, StatsD, Graphite 等常用服务的 exporters 用以处理告警的 alertmanager 其他各种支持工具 适用场景 Prometheus 适合记录任何纯数值的时间序列。它既适合以机器为中心的监控, 也适合监控高度动态的面向服务的体系结构. 它对多维数据收集和查询的支持在微服务的场景中拥有特别的优势.\nPrometheus 基于可靠性设计, 以保证在出现问题时可以快速进行问题诊断. 每个 Prometheus server 都是独立的, 不依赖于网络存储或其他远程服务. 当基础设施的其他部分出现故障时, 这种架构非常可靠, 另一方面, 它不需要配置大量的基础设施.\nPrometheus 不适合需要 100% 的准确性的场景, 例如记录单个的计费请求, 收集的数据可能不够详细和完整. 在这种情况下应使用其他系统来收集和分析计费数据, 使用 Prometheus 进行其余的监控.\n这里说的比较笼统, 从构建系统可观测性的监控来说, 我们有 Metrics , Tracing 和 Logging. 它们有各自的特点, Metrics 的特点是可聚合的, 它们是组成一个量计, 计数器或者直方图的最小单位. Logging 处理一系列离散事件. 而 Tracing 处理整个请求范围内的信息, 数据或元数据应当绑定到系统中单个事务对象的生命周期中.\nPrometheus 是个典型的 Metrics 系统, 它为系统打点, 追踪系统整体的运行情况. 比如, 记录 Web 系统中的所有请求的 HTTP 状态码, 当一段时间中 500 错误大量出现时, 可以通过配置的聚合和趋势分析发现问题并提供告警, 但它没有记录具体的请求内容, 想要复现错误的请求, 则需要 Tracing 和 Logging 系统进行进一步的诊断.\n快速入门 数据模型 Metric and Label Prometheus 在底层将所有属于同一指标名称, 同一标签集合的, 有时间戳标记的数据流存储为时间序列数据.\n数据模型的表示方式为\n1 \u0026lt;metric name\u0026gt;{\u0026lt;label name\u0026gt;=\u0026lt;label value\u0026gt;, ...} 且有以下规则\nmetric name 匹配正则 [a-zA-Z_:][a-zA-Z0-9_:]*, 其中 : 是用户自定义记录规则的标记, 不应该用在业务暴露的指标中\nlabel name 匹配正则 [a-zA-Z_][a-zA-Z0-9_]*, 其中以 __ 开头的是系统保留命名\nSample Sample 的 value 总是为一个 float64 值\n以关系型数据库来类比, metric_name 相当于表名, label_name 相当于列名, label_value 相当某一字段的值, 而 metric_value 和 timestamp 的列是系统自动生成的.\n比如如下名为 api_http_requests_total 指标表示了 API 所有的 HTTP 请求数, 其中标签 method 指定了方法, handler 指定了路径, 分别为 method=\u0026quot;POST\u0026quot; 和 handler=\u0026quot;/messages\u0026quot;, 此样本的值为 11\n1 api_http_requests_total{method=\u0026#34;POST\u0026#34;, handler=\u0026#34;/messages\u0026#34;} 11 1 2 3 4 5 6 7 8 9 10 11 12 13 14 CREATE TABLE `api_http_requests_total` ( `timestamp` timestamp, `method` varchar(255), `handler` varchar(255), `value` double ); SELECT * FROM `api_http_requests_total`; +------------+--------+-----------+-------+ | timestamp | method | handler | value | +------------+--------+-----------+-------+ | 1649235184 | POST | /messages | 11 | +------------+--------+-----------+-------+ Metric Prometheus 提供了以下一些类型 metrics 类型\nCounter Counter 类型代表一种样本数据单调递增的指标, 即除非监控系统发生了重置, 只增不减.\n例子: 系统接受的请求数, 系统错误数, 系统 uptime\nGauge Gauge 类型代表一种样本数据可以任意变化的指标, 即可增可减.\n例子: 当前实例线程数, 当前系统负载\nHistogram 和 Summary Histogram 和 Summary 用以对数据进行采样并储存其分布情况. 不同的是, Histogram 指定其配置的区间, 而 Summary 配置其分位数.\n举一个具体的例子, 假设需要统计某个 WEB 页面的响应时间, 使用 Histogram 时, 需要配置其响应时间区间, \u0026lt;10ms, 10ms-100ms, 100ms-1000ms, \u0026gt;1000ms, 返回的数据如下\n1 2 3 4 5 6 http_response_latency_range_bucket{le=\u0026#34;0.01\u0026#34;} 123 http_response_latency_range_bucket{le=\u0026#34;0.1\u0026#34;} 214 http_response_latency_range_bucket{le=\u0026#34;1\u0026#34;} 215 http_response_latency_range_bucket{le=\u0026#34;+Inf\u0026#34;} 216 http_response_latency_range_sum 2.888716127000002 http_response_latency_range_count 216 使用 Summary 时, 则配置 0.5, 0.9, 0.99, 代表了其50分位, 即中位数, 90分位, 99分位的值\n1 2 3 4 5 http_response_latency{quantile=\u0026#34;0.5\u0026#34;} 0.012352463 http_response_latency{quantile=\u0026#34;0.9\u0026#34;} 0.014458005 http_response_latency{quantile=\u0026#34;0.99\u0026#34;} 0.017316173 http_response_latency_sum 2.888716127000002 http_response_latency_count 216 此时可以看到, 这个 HTTP 接口一共接受了 216 次请求, 一共耗时使用了 2.88s, Histogram 展示了具体数值分布, 123 个在 10ms 内, 有 216 - 215 = 1 个请求耗时超过了 1000ms. Summary 展示了分布的百分位, 中位数是 0.012s, 99分位是 0.017s.\n通常我们使用 Histogram 即可, Summary 会使用较多的内存构造一个滑动窗口来做统计.\n注意事项 每个键值标签对的唯一组合都代表一个新的时间序列, 这会显著增加暴露的指标数和存储的数据量. 不要使用标签存储具有高基数, 即拥有许多不同的标签值的维度, 例如用户id, restful 的实际路径参数等.\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 // Good http_request_total{path=\u0026#34;users/{:user_id}/info\u0026#34;} // Bad http_request_total{path=\u0026#34;users/1/info\u0026#34;} http_request_total{path=\u0026#34;users/2/info\u0026#34;} http_request_total{path=\u0026#34;users/3/info\u0026#34;} http_request_total{path=\u0026#34;users/4/info\u0026#34;} // Good crawler_failure_total{target=\u0026#34;tiktok\u0026#34;,scope=\u0026#34;user\u0026#34;} // Bad crawler_failure_total{target=\u0026#34;tiktok\u0026#34;,user=\u0026#34;damonlvu\u0026#34;} crawler_failure_total{target=\u0026#34;tiktok\u0026#34;,user=\u0026#34;77777777777ge\u0026#34;} 在 Prometheus 中, Metric 和 Label 的命名应该总是使用 snake_case 形式, 以便后续的处理归类分割等操作.\n一个 Metric 的前缀总应该使用应用名, 可以理解为一个命名空间, 例如\nprometheus_notifications_total (Prometheus 的内部指标) doris_consumption_latency_seconds (doris 的消费延时) crawler_failure_total (爬虫的总失败数) crawler_request_total (爬虫的总请求数) 一个 Metric 总应该以其单位的复数形式为后缀, 并且单位应该尽量统一, 如果是一个累积的计数, 总应该使用 total\nnode_memory_usage_bytes http_requests_total process_cpu_seconds_total 抓取设置 通过 Prometheus Operator 的 ServiceMonitor 对象, 可以相对便捷的, 通过不直接修改 prometheus config 的方式添加抓取目标.\n1 2 3 4 5 6 7 8 9 10 11 12 13 apiVersion: monitoring.coreos.com/v1 kind: ServiceMonitor metadata: name: example-service-monitor labels: team: ops spec: selector: matchLabels: svc-label-key: svc-label-value endpoints: - port: 80 - path: /metrics 上面的实例指定了一个名为 example-service-monitor 的 ServiceMonitor, 它会选择所有 svc-label-key 的值为 svc-label-value 的 Service 进行监控, 目标端口为 80, HTTP 路径为 /metrics. Service 背后可能存在超过一个的无状态的 Pod, 他们会被自动发现.\nPrometheus Operator 会解析 ServiceMonitor 对象, 生成相应的抓取设置到 prometheus config.\n指标选择 一般 exporter 会采集很多的指标, 比如 jvm 的运行情况, http 请求情况等等. Google 在 SRE Handbook 中提出了四个黄金信号: 延迟, 流量, 错误数, 饱和度. 实际操作中可以使用 USE 或 RED 方法作为指导, USE(Utilization, Saturation, Errors) 用于资源, RED(Rate, Errors, Duration) 用于服务.\n一般的在线服务, 比如 Web 服务, 数据库等, 一般关心请求速率, 延迟和错误率, 使用 RED 方法; 一般的离线服务, 如日志处理, 消息队列等, 一般关注队列数量, 进行中的数量, 处理速度以及发生的错误, 使用 USE 方法.\nRate 速率 1 sum(rate(http_server_requests_seconds_count[5m])) by (method, uri, job) 统计访问的 QPS\nErrors 错误 1 rate(http_server_requests_seconds_count{status=~\u0026#34;^5..$\u0026#34;}[5m]) / rate(http_server_requests_seconds_count[5m]) 统计 HTTP 状态码为 5xx 的比例\nDuration 请求时间 1 sum by (job, uri, method) (rate(http_server_requests_seconds_sum[5m]) / rate(http_server_requests_seconds_count[5m])) 统计平均请求时间\n参考资料 What is Prometheus?\nMetrics, tracing, and logging\ncontainer-monitor-book\n","date":"2022-04-17T16:30:08+08:00","image":"https://memwey.github.io/p/prometheus-%E4%BB%8E%E5%85%A5%E9%97%A8%E5%88%B0%E6%94%BE%E5%BC%83/images/Prometheus.svg","permalink":"https://memwey.github.io/p/prometheus-%E4%BB%8E%E5%85%A5%E9%97%A8%E5%88%B0%E6%94%BE%E5%BC%83/","title":"Prometheus 从入门到放弃"},{"content":"从一家创业公司离职, 去另外一家创业公司.\n在家待了一个月多一点, 期间解决了一下家里的大事小情, 复习刷题和面试, 开始巴西柔术的学习, 控制饮食和运动, 刷 Bilibili 什么的. 然而最重要的婚礼因为突如其来的疫情只能被迫延后了.\n不得不说, 广州的机会真的不多. 一开始找了几家中等级别的公司面试练手, 结果发现没有达到那种面的我怀疑人生然后努力复习的结果, 随手就面过, 回家接着摸鱼. 然后抱有比较大希望的腾讯和字节都因为各种各样奇怪的原因连面试都没有, 不得不说和某些公司就是没有缘分.\n离开的原因 其实我觉得还是离开上一家公司的太迟了. 年初拿到 Edison 的 Offer 的时候就应该离开了.\n有种观点认为, 对于一个创业来说, 最重要的是团队, 尤其是最初共同创业的团队, 业务都是在其次. 但是上一家公司在去年第三季度的时候就出现了一波离职潮, 基本上所有作为公司创始成员的老员工都离职了. 曾经工资都发不出来的时期没有离开, 现在拿到融资了业务有一些眉目了反而离开了, 可能这就是可以共患难而不能同富贵吧.\n当然可能并不是钱的问题. 老板自己承认自己有暴力沟通的问题. 不过, 能不能认识到是一回事, 能不能控制是另外一回事. 人总不可能不犯错, 往好了说是老板真性情, 往坏了说就是老板抓住一点错误就大做文章, 哭爹骂娘什么的.\n创业有一个相当不好平衡的问题. 创业公司当然希望团队成员能力超群, 能解决各种各样的问题, 但是除了少数带有光环的创业公司, 资金一般都不是那么充裕的. 对于优秀的求职者来说, 既然是创业, 风险更高, 为何要放弃差不多甚至更低的短期回报, 来承担更高的风险呢. 这也是上面提到的最初共同创业的团队非常重要的原因之一.\n在上一家公司, 老板可能是想出了解决办法. 团队中少数的优秀员工负责, 带领一些能力一般的员工. 作为后端负责人, 经常梳理产品设计, 团队代码审查就把工作时间占满了, 写代码只能加班. 有次私下跟老板吐槽一个产品经理, 根本发现不了用户需求, 一个功能上线了四五版, 都解决不了用户的问题. 老板一句话顶回来了: 你知道她一个月多少钱吗, 五千.\n在这种同事能力参差, 而老板有时又格外苛责的情况下, 压力确实比较大, 情绪比较消沉, 有段时间天天想请假, 想到要去上班就头疼. 最终还是决定离职了.\n选择的原因 又来到一家创业公司其实自己都蛮没想到的, 毕竟最初的构想是去大公司做一些基础架构的开发, 远离枯燥重复的业务开发.\n这家公司最吸引的可能就是微信顶级产品经理带队吧. 这几年的工作也算是接触过不少产品经理, 有厉害的也有水平一般的, 感觉产品经理是一个有手就能做的职业, 但是水平高的产品经理确实无法替代. 想近距离接触一下传说中的微信之母, 直接向张小龙汇报的产品经理, 看看她们的思维和做事是什么样的.\n另外, 这家公司光环比较强, 资金比较充足, 薪酬福利什么的都挺不错的, 完美的解决了创业公司的一些问题.\n不过个人还是觉得在目前公司主要产品上, 有一些隐患, 在熟人IM和陌生人社交上有点定位不清. 而且在熟人IM上, 很难看到短期内的盈利空间. 但是毕竟不是专业的产品经理, 所有的看法都是基于已有的产品, 比如微信, 陌陌, Soul 什么的. 厉害的产品经理可以发现别人发现不到的需求, 万一呢.\n","date":"2021-06-06T23:29:39+08:00","permalink":"https://memwey.github.io/p/%E4%B8%80%E4%B8%AA%E7%A6%BB%E8%81%8C%E5%B0%8F%E8%AE%B0/","title":"一个离职小记"},{"content":"结构推测 今天与人争执的时候觉得应该探究一下 Redis 中 ZINTERSTORE 的实现. 先看文档中的描述\nZINTERSTORE destination numkeys key [key \u0026hellip;] [WEIGHTS weight [weight \u0026hellip;]] [AGGREGATE SUM|MIN|MAX]\nAvailable since 2.0.0.\nTime complexity: O(NK)+O(Mlog(M)) worst case with N being the smallest input sorted set, K being the number of input sorted sets and M being the number of elements in the resulting sorted set.\n大致意思就是最坏情况下时间复杂度是 O(N*K)+O(M*log(M)), 其中 N 是输入中元素最少的 sorted set 的元素数目, K 是输入的 sorted set 的数量, M 是结果中的 sorted set 中元素的数目.\n其实光从时间复杂度就能推测出来大致的操作了. O(M*log(M)) 这个复杂度很有可能是一次排序操作, 而且和结果中的元素数目相关, 那么很有可能是先取交集之后得出 M 个元素, 再在 M 个元素中进行排序的. 当然, 也有可能是相应的, 在有序的序列中进行插入的操作.\n而 N 是最小的 sorted set 的元素个数. 这个一开始我有点想不明白, 难道不应该是最大的才对吗, 因为这里我还是想着去遍历其他的 sorted set 进行比较. 但是思考一下, sorted set 也是 set 嘛, 完全可以使用 O(1) 的效率在其中进行查找. 这样实际就变成了分别在 (K - 1) 个 sorted set 中寻找 N 个元素, 这样自然就是 O(N*K) 了.\n源码分析 以下源码基于 Redis 3.0 分析, 实际的函数操作为\n1 2 /* https://github.com/redis/redis/blob/3.0/src/t_zset.c#L1905 */ void zunionInterGenericCommand(redisClient *c, robj *dstkey, int op) 这里我们可以看到, 在 Redis 的源码中将 ZINTERSTORE 和 ZUNIONSTORE 放在了一起处理, 使用 op 做区分.\n随后是一段漫长的代码, 主要是处理输入参数的, 比如要操作的 sorted set 的列表, 存到了 src 中; 然后处理 WEIGHTS 和 AGGREGATE. 代码比较长而且逻辑也很简单.\n1 2 3 4 5 /* https://github.com/redis/redis/blob/3.0/src/t_zset.c#L1993 */ /* sort sets from the smallest to largest, this will improve our * algorithm\u0026#39;s performance */ qsort(src,setnum,sizeof(zsetopsrc),zuiCompareByCardinality); 然后这里把所有 sorted set 按元素的个数从小到大排列, 以提高效率. 随后是具体的取交集的代码.\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 /* https://github.com/redis/redis/blob/3.0/src/t_zset.c#L2001 */ if (op == REDIS_OP_INTER) { /* Skip everything if the smallest input is empty. */ if (zuiLength(\u0026amp;src[0]) \u0026gt; 0) { /* Precondition: as src[0] is non-empty and the inputs are ordered * by size, all src[i \u0026gt; 0] are non-empty too. */ zuiInitIterator(\u0026amp;src[0]); while (zuiNext(\u0026amp;src[0],\u0026amp;zval)) { double score, value; score = src[0].weight * zval.score; if (isnan(score)) score = 0; for (j = 1; j \u0026lt; setnum; j++) { /* It is not safe to access the zset we are * iterating, so explicitly check for equal object. */ if (src[j].subject == src[0].subject) { value = zval.score*src[j].weight; zunionInterAggregate(\u0026amp;score,value,aggregate); } else if (zuiFind(\u0026amp;src[j],\u0026amp;zval,\u0026amp;value)) { value *= src[j].weight; zunionInterAggregate(\u0026amp;score,value,aggregate); } else { break; } } /* Only continue when present in every input. */ if (j == setnum) { tmp = zuiObjectFromValue(\u0026amp;zval); znode = zslInsert(dstzset-\u0026gt;zsl,score,tmp); incrRefCount(tmp); /* added to skiplist */ dictAdd(dstzset-\u0026gt;dict,tmp,\u0026amp;znode-\u0026gt;score); incrRefCount(tmp); /* added to dictionary */ if (sdsEncodedObject(tmp)) { if (sdslen(tmp-\u0026gt;ptr) \u0026gt; maxelelen) maxelelen = sdslen(tmp-\u0026gt;ptr); } } } zuiClearIterator(\u0026amp;src[0]); } } 当然, 如果按元素数从小到大排序的第一个 sorted set 元素数为 0, 那就可以直接返回了, 随后在此 sorted set 上建立一个 Iterator, 主要就是帮助在 sorted set 上做遍历的, 因为在 sorted set 中, 遍历不是一个常用操作, 排序才是.\n然后就是通过 while (zuiNext(\u0026amp;src[0],\u0026amp;zval)) 取出第一个 sorted set 中的每一个元素, 再用 for (j = 1; j \u0026lt; setnum; j++) 将其在每一个其他的 sorted set 中查找一遍.\n当两个 sorted set 指向同一个对象是, 那么毫无疑问一定会有同样的元素. 否则就在 src[j] 中查找当前元素. zuiFind(\u0026amp;src[j],\u0026amp;zval,\u0026amp;value) 实现了这个操作. 具体的代码在后面分析. 如果找不到的话, 则没有必要继续找下去了, 跳出即可.\n查找的过程中也使用了 zunionInterAggregate(\u0026amp;score,value,aggregate) 来更新当前元素的 score, 具体的 score 更新规则是根据 AGGREGATE 参数来定的.\n当元素在所有的 sorted set 中时, 就可以把这个元素添加进结果的 sorted set 中了. 这里就是根据 zval 和 score 往 dstzset 里面插入元素. 因为 sorted set 里面既有 dict 也有 skiplist, 所以两个都要添加.\n这里还有一个操作就是更新最大元素的长度, 这个和 sorted set 的内部优化有关.\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 /* https://github.com/redis/redis/blob/3.0/src/t_zset.c#L2119 */ if (dbDelete(c-\u0026gt;db,dstkey)) { signalModifiedKey(c-\u0026gt;db,dstkey); touched = 1; server.dirty++; } if (dstzset-\u0026gt;zsl-\u0026gt;length) { /* Convert to ziplist when in limits. */ if (dstzset-\u0026gt;zsl-\u0026gt;length \u0026lt;= server.zset_max_ziplist_entries \u0026amp;\u0026amp; maxelelen \u0026lt;= server.zset_max_ziplist_value) zsetConvert(dstobj,REDIS_ENCODING_ZIPLIST); dbAdd(c-\u0026gt;db,dstkey,dstobj); addReplyLongLong(c,zsetLength(dstobj)); if (!touched) signalModifiedKey(c-\u0026gt;db,dstkey); notifyKeyspaceEvent(REDIS_NOTIFY_ZSET, (op == REDIS_OP_UNION) ? \u0026#34;zunionstore\u0026#34; : \u0026#34;zinterstore\u0026#34;, dstkey,c-\u0026gt;db-\u0026gt;id); server.dirty++; } else { decrRefCount(dstobj); addReply(c,shared.czero); if (touched) notifyKeyspaceEvent(REDIS_NOTIFY_GENERIC,\u0026#34;del\u0026#34;,dstkey,c-\u0026gt;db-\u0026gt;id); } zfree(src); 随后就是收尾工作. 如果目标的坑上已经有值了, 就毫不犹豫的干掉它. 然后再看作为结果的 sorted set. 如果它满足转化为 ziplist 的条件, 就可以把它转化为 ziplist. 后面是一些 hook 的通知, 可以暂时忽略. 如果结果为空, Integer reply 会返回 0, 否则会返回结果中元素的个数.\n至此大致流程已经结束了. 如同推测的那样, 算法复杂度完美的反映了操作的内部过程和数据结构. 不过, 我们还有几个问题没有解决. zuiFind 中的具体操作是什么, ziplist 又是什么.\n搁这搁这 这个标题充分提现了递归的思想. 学习新东西, 然后发现另一些新东西, 然后再学习这些新东西, 然后\u0026hellip;\u0026hellip;\n首先来看 zuiFind\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 /* https://github.com/redis/redis/blob/3.0/src/t_zset.c#L1826 */ int zuiFind(zsetopsrc *op, zsetopval *val, double *score) { if (op-\u0026gt;subject == NULL) return 0; if (op-\u0026gt;type == REDIS_SET) { if (op-\u0026gt;encoding == REDIS_ENCODING_INTSET) { if (zuiLongLongFromValue(val) \u0026amp;\u0026amp; intsetFind(op-\u0026gt;subject-\u0026gt;ptr,val-\u0026gt;ell)) { *score = 1.0; return 1; } else { return 0; } } else if (op-\u0026gt;encoding == REDIS_ENCODING_HT) { dict *ht = op-\u0026gt;subject-\u0026gt;ptr; zuiObjectFromValue(val); if (dictFind(ht,val-\u0026gt;ele) != NULL) { *score = 1.0; return 1; } else { return 0; } } else { redisPanic(\u0026#34;Unknown set encoding\u0026#34;); } } else if (op-\u0026gt;type == REDIS_ZSET) { zuiObjectFromValue(val); if (op-\u0026gt;encoding == REDIS_ENCODING_ZIPLIST) { if (zzlFind(op-\u0026gt;subject-\u0026gt;ptr,val-\u0026gt;ele,score) != NULL) { /* Score is already set by zzlFind. */ return 1; } else { return 0; } } else if (op-\u0026gt;encoding == REDIS_ENCODING_SKIPLIST) { zset *zs = op-\u0026gt;subject-\u0026gt;ptr; dictEntry *de; if ((de = dictFind(zs-\u0026gt;dict,val-\u0026gt;ele)) != NULL) { *score = *(double*)dictGetVal(de); return 1; } else { return 0; } } else { redisPanic(\u0026#34;Unknown sorted set encoding\u0026#34;); } } else { redisPanic(\u0026#34;Unsupported type\u0026#34;); } } 先忽略掉 set 的操作, 来看 sorted set. 我们又见到了收尾工作时出现过的 ziplist.\nThe ziplist is a specially encoded dually linked list that is designed to be very memory efficient. It stores both strings and integer values, where integers are encoded as actual integers instead of a series of characters. It allows push and pop operations on either side of the list in O(1) time. However, because every operation requires a reallocation of the memory used by the ziplist, the actual complexity is related to the amount of memory used by the ziplist.\n查了一下资料, 这是 Redis 在面对小元素时可以做的一个内存优化, 本体是一个经过特殊编码的双向链表. 经过特殊编码后的数据会变得更加紧凑, 连续的内存使用也对于缓存更加友好. 有两个配置决定了 sorted set 中使用 ziplist 的阈值.\n1 2 #define REDIS_ZSET_MAX_ZIPLIST_ENTRIES 128 #define REDIS_ZSET_MAX_ZIPLIST_VALUE 64 图. 有序集合\n然后我们尴尬的发现, 在 ziplist 查找一个元素实际上是一个遍历, 时间复杂度为 O(N), 如下\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 /* https://github.com/redis/redis/blob/3.0/src/t_zset.c#L915 */ unsigned char *zzlFind(unsigned char *zl, robj *ele, double *score) { unsigned char *eptr = ziplistIndex(zl,0), *sptr; ele = getDecodedObject(ele); while (eptr != NULL) { sptr = ziplistNext(zl,eptr); redisAssertWithInfo(NULL,ele,sptr != NULL); if (ziplistCompare(eptr,ele-\u0026gt;ptr,sdslen(ele-\u0026gt;ptr))) { /* Matching element, pull out score. */ if (score != NULL) *score = zzlGetScore(sptr); decrRefCount(ele); return eptr; } /* Move to next element. */ eptr = ziplistNext(zl,sptr); } decrRefCount(ele); return NULL; } 不过当 zset 使用 REDIS_ENCODING_SKIPLIST 作为 encoding 的时候, 使用 Hash table 做查询的时间复杂度是 O(1) 这是肯定的.\n当然, 这里面其实还有很多细节没有说到, 比如 ziplist 的内部表示, 和 zset 混在一起的 set, zset 中的 dict 和 skiplist 的详细分析等等. 下次有机会的吧.\n参考资料 The ziplist representation 压缩列表 — Redis 设计与实现 ","date":"2021-04-21T20:30:43+08:00","permalink":"https://memwey.github.io/p/redis-zinterstore/","title":"Redis ZINTERSTORE"},{"content":"基础知识 LRU (Least recently used) 是一个非常常用的缓存置换算法.\n在缓存空间有限的情况下, 在新的数据写入时, 需要淘汰一些旧数据. 一般期望最不可能被继续访问的数据淘汰. 由于无法对未来的情况进行预测, 只能基于现有的信息推测.\nLRU 基于这样一个假定, 在一个时间点上, 如果一个数据距离上次被访问的时间越长, 则这个数据在未来被访问的可能性越小. 所以, 应该淘汰掉距离上次被访问的时间最久的数据.\n常见的 LRU 实现是使用一个双向链表, 当 Item 被访问时, 将其移动到链表的头部. 当缓存不足时, 从链表的尾部开始淘汰.\n单纯的双向链表的实现实际上是不太符合现实的. 一般的, 我们希望缓存可以尽快被检索到, 而在双向链表中检索 Item 的效率是 O(n), 特别是检索的 Item 在链表中不存在时, 效率稳定的是 O(n). 这样, 在缓存系统中维护这个双向链表的成本是非常高的. 一般的, 会将 哈希表 或者 二叉搜索树 和双向链表组合起来, 在更高效率的数据结构中记录 Key, 并在 Key 中记录 Item 在双向链表中的指针.\n另外的, 在并发量较大的时候, 双向链表中的操作需要加锁, 否则链表很容易出问题.\n具体实现 Redis 2.8 在较早版本的 Redis 上, 并没有实现 LRU. 在后续 2.8 添加的时候, 并没有使用常见的双向链表的方式来实现 LRU, 而使用了一个近似的实现.\n从空间和时间上考虑, Redis 中的 Key 的数量可能非常的多, 双向链表可能会非常大, 占用内存非常多; 另一方面, Redis 中的操作可能也非常频繁, 每一次访问都需要操作一次双向链表, 在时间上也显得非常不划算.\nAntirez 在 Redis Object 中挤出了 24 个位元 bits, 并用其存储按秒计算的 unix timestamp 的低 24 位. 这个被称为 LRU clock.\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 /* https://github.com/redis/redis/blob/3.0/src/redis.h#L420 */ /* A redis object, that is a type able to hold a string / list / set */ /* The actual Redis Object */ #define REDIS_LRU_BITS 24 #define REDIS_LRU_CLOCK_MAX ((1\u0026lt;\u0026lt;REDIS_LRU_BITS)-1) /* Max value of obj-\u0026gt;lru */ #define REDIS_LRU_CLOCK_RESOLUTION 1000 /* LRU clock resolution in ms */ typedef struct redisObject { unsigned type:4; unsigned encoding:4; unsigned lru:REDIS_LRU_BITS; /* lru time (relative to server.lruclock) */ int refcount; void *ptr; } robj; 24 个 bits 明显不够存储一个完整的时间戳, 当第二十四位向前进位的时候, 就会发生溢出. 此时, 最近被访问的 Item 的 LRU clock 反而较小, 更容易被淘汰. 考虑到这个溢出需要 194 天, 而 Redis 中的操作应该比较频繁, 所以 antirez 认为这个问题可以接受.\n理论上, 可以精心构造一些数据, 让 Redis 的 LRU 失效. 比如, 总是在溢出前访问一个 Item, 这个 Item 的 LRU clock 总是很大, 虽然这个 Item 的访问周期总是 194 天才访问一次, 但是它总不会被淘汰.\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 /* https://github.com/redis/redis/blob/3.0/src/db.c#L43 */ robj *lookupKey(redisDb *db, robj *key) { dictEntry *de = dictFind(db-\u0026gt;dict,key-\u0026gt;ptr); if (de) { robj *val = dictGetVal(de); /* Update the access time for the ageing algorithm. * Don\u0026#39;t do it if we have a saving child, as this will trigger * a copy on write madness. */ if (server.rdb_child_pid == -1 \u0026amp;\u0026amp; server.aof_child_pid == -1) val-\u0026gt;lru = LRU_CLOCK(); return val; } else { return NULL; } } 接下来的问题在于如何找到最久没有被访问的 Item. 如果一定要找到最久没有被访问到的 Item, 那么需要遍历所有的 Key, 而且在遍历的过程中, 要么禁止在这期间做任何的访问操作, 要么可能出现找到的 Key 恰好又刚刚被访问到的问题.\nAntirez 在这里又使用了一个近似的实现, 随机选取 3 个 Key, 把他们之中最久没有被访问到的淘汰. 随后, 这个数值变成了可配置项 maxmemory-samples , 默认值是 5. 考虑到选出的结果不一定是最好的, 但是很大可能不是一个坏的结果, 即选出一个非常近被访问的 Item, 这个实现还算可以接受.\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 /* https://github.com/redis/redis/blob/2.8/src/redis.c#L2982 */ /* volatile-lru and allkeys-lru policy */ else if (server.maxmemory_policy == REDIS_MAXMEMORY_ALLKEYS_LRU || server.maxmemory_policy == REDIS_MAXMEMORY_VOLATILE_LRU) { for (k = 0; k \u0026lt; server.maxmemory_samples; k++) { sds thiskey; long thisval; robj *o; de = dictGetRandomKey(dict); thiskey = dictGetKey(de); /* When policy is volatile-lru we need an additional lookup * to locate the real key, as dict is set to db-\u0026gt;expires. */ if (server.maxmemory_policy == REDIS_MAXMEMORY_VOLATILE_LRU) de = dictFind(db-\u0026gt;dict, thiskey); o = dictGetVal(de); thisval = estimateObjectIdleTime(o); /* Higher idle time is better candidate for deletion */ if (bestkey == NULL || thisval \u0026gt; bestval) { bestkey = thiskey; bestval = thisval; } } } Redis 3.0 Antirez 在 3.0 版本中进一步提升了近似算法的准确性. 一个显而易见的方法是, 通过过去累计的信息来提升准确性.\nRedis 中维护了一个默认大小为 16 的 pool, 里面存储了备选的 Key. 当需要淘汰时, 从随机选择的 N 个 Key 中与 pool 中的 Key 做对比, 在 pool 中维护其中最久没有被访问到的 16 个 Key, 然后在 pool 中淘汰其中最久没有被访问到的 Item. 这个 pool 非常类似于小顶堆.\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 /* https://github.com/redis/redis/blob/3.0/src/redis.c#L3275 */ /* volatile-lru and allkeys-lru policy */ else if (server.maxmemory_policy == REDIS_MAXMEMORY_ALLKEYS_LRU || server.maxmemory_policy == REDIS_MAXMEMORY_VOLATILE_LRU) { struct evictionPoolEntry *pool = db-\u0026gt;eviction_pool; while(bestkey == NULL) { evictionPoolPopulate(dict, db-\u0026gt;dict, db-\u0026gt;eviction_pool); /* Go backward from best to worst element to evict. */ for (k = REDIS_EVICTION_POOL_SIZE-1; k \u0026gt;= 0; k--) { if (pool[k].key == NULL) continue; de = dictFind(dict,pool[k].key); /* Remove the entry from the pool. */ sdsfree(pool[k].key); /* Shift all elements on its right to left. */ memmove(pool+k,pool+k+1, sizeof(pool[0])*(REDIS_EVICTION_POOL_SIZE-k-1)); /* Clear the element on the right which is empty * since we shifted one position to the left. */ pool[REDIS_EVICTION_POOL_SIZE-1].key = NULL; pool[REDIS_EVICTION_POOL_SIZE-1].idle = 0; /* If the key exists, is our pick. Otherwise it is * a ghost and we need to try the next element. */ if (de) { bestkey = dictGetKey(de); break; } else { /* Ghost... */ continue; } } } } pool 中排序操作的核心代码在 evictionPoolPopulate 函数中\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 /* https://github.com/redis/redis/blob/3.0/src/redis.c#L3145 */ #define EVICTION_SAMPLES_ARRAY_SIZE 16 void evictionPoolPopulate(dict *sampledict, dict *keydict, struct evictionPoolEntry *pool) { int j, k, count; dictEntry *_samples[EVICTION_SAMPLES_ARRAY_SIZE]; dictEntry **samples; /* Try to use a static buffer: this function is a big hit... * Note: it was actually measured that this helps. */ if (server.maxmemory_samples \u0026lt;= EVICTION_SAMPLES_ARRAY_SIZE) { samples = _samples; } else { samples = zmalloc(sizeof(samples[0])*server.maxmemory_samples); } count = dictGetSomeKeys(sampledict,samples,server.maxmemory_samples); for (j = 0; j \u0026lt; count; j++) { unsigned long long idle; sds key; robj *o; dictEntry *de; de = samples[j]; key = dictGetKey(de); /* If the dictionary we are sampling from is not the main * dictionary (but the expires one) we need to lookup the key * again in the key dictionary to obtain the value object. */ if (sampledict != keydict) de = dictFind(keydict, key); o = dictGetVal(de); idle = estimateObjectIdleTime(o); /* Insert the element inside the pool. * First, find the first empty bucket or the first populated * bucket that has an idle time smaller than our idle time. */ k = 0; while (k \u0026lt; REDIS_EVICTION_POOL_SIZE \u0026amp;\u0026amp; pool[k].key \u0026amp;\u0026amp; pool[k].idle \u0026lt; idle) k++; if (k == 0 \u0026amp;\u0026amp; pool[REDIS_EVICTION_POOL_SIZE-1].key != NULL) { /* Can\u0026#39;t insert if the element is \u0026lt; the worst element we have * and there are no empty buckets. */ continue; } else if (k \u0026lt; REDIS_EVICTION_POOL_SIZE \u0026amp;\u0026amp; pool[k].key == NULL) { /* Inserting into empty position. No setup needed before insert. */ } else { /* Inserting in the middle. Now k points to the first element * greater than the element to insert. */ if (pool[REDIS_EVICTION_POOL_SIZE-1].key == NULL) { /* Free space on the right? Insert at k shifting * all the elements from k to end to the right. */ memmove(pool+k+1,pool+k, sizeof(pool[0])*(REDIS_EVICTION_POOL_SIZE-k-1)); } else { /* No free space on right? Insert at k-1 */ k--; /* Shift all elements on the left of k (included) to the * left, so we discard the element with smaller idle time. */ sdsfree(pool[0].key); memmove(pool,pool+1,sizeof(pool[0])*k); } } pool[k].key = sdsdup(key); pool[k].idle = idle; } if (samples != _samples) zfree(samples); } 参考资料 Random notes on improving the Redis LRU algorithm Using Redis as an LRU cache ","date":"2020-12-25T14:26:24+08:00","permalink":"https://memwey.github.io/p/redis-lru/","title":"Redis LRU"},{"content":"原本的台式机, E3-1231v3 搭配上在挖矿狂潮前买的 GTX 1070, 在这个普遍挤牙膏的时期感觉再战三年不成问题. 不过既然有了自己的书房, 书房里没有电脑是万万不能的. 看了一下自己的钱包和京东的无货, 决定用 新平台 + 老显卡, 老平台 + 入门显卡 这样的组合, 让一台电脑变成两台.\n挑选过程 新平台暂且不表, 有空另外记录. 这段其实跳过也行, 都是一些流水账.\n首先还是决定给老平台增加一些便携性, 毕竟性能够用就好, 租房住的生活还是要考虑搬家的, 之前的全铝加钢化玻璃机箱搬起来确实不方便. 另外, 对之前的乞丐版主板和电源也都不太满意, 但是问题最大的就是主板, LGA 1150 平台的 ITX 主板数量稀少且价格昂贵. 转换思路想一想, 机箱, 主板, 电源, 这不就是一个准系统吗.\n淘宝逛了一下发现, 主要是 DELL 和 HP 的 SFF (Small Form Factor) 型准系统比较符合需求. 主要型号包括 DELL OptiPlex 3020, DELL OptiPlex 7020, DELL OptiPlex 9020, DELL Precision T1700, HP ProDesk 400 G1, HP ProDesk 600 G1, HP ProDesk 800 G1, HP Z230. 同系列的产品很好比较, 数字越大约好, 不过其实也没太大区别. HP 的机器相比 DELL 的稍微大一些, 扩展性稍强.\nDELL Precision T1700 在以上型号中脱颖而出的原因可能就是因为它是 Workstation 和 C226 主板芯片组和它不属于搞的人头晕的家族式型号吧.\n系统介绍 尺寸: 290.00mm * 92.60mm * 312.00mm 体积: 8.38L 重量: 5.30KG 电源输出: 255W 图. 机箱前面板\n体积完全可以称得上小巧. C226 主板可以让 LGA 1150 的 E3-1231v3 和 DDR3 的两条内存条发挥余热和体验工作站主板. 支持一张半高显卡可以在 E3-1231v3 没有核心显卡和一定的游戏需求中找到一个能用的解决方案.\n硬件配置 CPU: Intel Xeon E3-1231 v3 @ 3.40GHz 4C8T RAM: G.SKILL 8G 1600MHz (x2) GPU: NVIDIA GeForce GTX 1650 4G SSD: GLOWAY STK240GS3-S7 Wi-Fi: Intel Dual Band Wireless-AC 7265 其余诸如主板, 机箱, 电源, 散热器都是准系统自带的.\n由于显卡必须要 单槽位 的 半高 显卡, 所以这块 翔升 GTX1650 4GD5 战刀 应该是目前(2020-11-01)能买到的现在已经买不到了, 刚看了一下最强的显卡了.\n图. 但是长的有点丑\n其余配件就都是从老机器上拆下来的了, 唯一有点例外的是无线网卡, 因为是 PCIe 网卡, 之前是全高挡板, 淘宝算上邮费 7 块钱买了个半高挡板解决. 从北京快递过来邮费只要 4 块钱, 我也是惊了.\n装机体验 图. 机箱后面板\n小小机身拥有前置 4 个 USB 加后置 6 个 USB, 数量惊人. 甚至还带了 PS/2 键鼠接口和 RS-232 串行接口. 显示输出带了两个 DP 和一个 VGA 这对新老搭档, 缺少中青代的 HDMI 和 DVI 可能会有点不便. 用独立显卡就无所谓了.\n机箱完全是免螺丝拆装的, 维护性很好. 机箱内部有大量塑料的部分, 主要起调整风道和固定的作用. 电源和前面板风扇从前面板下方吸风, 从机箱后部排出热风.\n图. 机箱内部\n虽然主板上有三个 SATA 接口, 但实际上只有一个标准的硬盘供电, 凑合着和一个非标准的光驱供电一起从主板上引出, 所以想要使用超过一个硬盘要想想办法, 可以使用一转二的硬盘供电什么的.\n如果使用单个固态硬盘的话, 直接把固态硬盘塞到那个 3.5 寸机械硬盘位就好了, 不过有机械硬盘的话, 固态硬盘就不太好安放了, 好在空间还算多, 固态硬盘也很坚强, 找个地方塞一下问题不大.\n图. 凌乱的内部\n非标准的电源只有 255W, 而且只有一个 8pin 的主板供电和一个 4pin 的 CPU 供电, 没有任何 PCIe 供电. 不过反正半高显卡也基本都是能被 PCIe 16X 的 75W 供电满足的.\n四个标准台式机内存插槽够用, 给已经成为时代的眼泪的 DDR3 内存找一个家. 插槽上有清晰的编号, 按照顺序插上即可.\n主板提供了两个 PCIe 插槽, 一个全长 x16, 另一个是 x4. 但是问题是 16x 的反而 4x 的下面, 而且距离再下面的电源很近, 所以要想让显卡充分发挥只能用单槽位的. 不过这块 翔升 GTX1650 4GD5 战刀 是涡轮散热, 从显卡顶端的风扇吸风到尾部排出, 和机箱原有的前面板风扇风道一致, 散热应该还好. 有机友反馈显卡太长会挡住部分 SATA 接口, 这块显卡因为更短了, 所以没有这个情况.\n主板上真的是一个多余的接口都没有, 导致 PCIe 无线网卡蓝牙功能所需的 USB 插头无处安放. 好吧, 小问题.\n机箱还有一个内置的小音响, 虽然音质什么的只能说是听个响, 甚至还不怎么响, 但是应急什么的还是挺好用的.\n原配的散热器是全铝的, 之前甚至都没见过这么寒酸的散热器. 在万能的淘宝上发现了可用的铜芯散热器 J9G15, 据商家所说是原配给更高端的 XE2 机型的散热器, 比全铝的重了有 90 克. 花费 46.8 入手一只换上, 感觉温度确实下降了不少.\n图. 机箱大小参考\n参考资料 Dell Precision T1700 小型计算机 用户手册 Dell Precision T1700 SFF 攒机与使用 年轻人的第一台Precision ","date":"2020-12-04T00:52:03+08:00","permalink":"https://memwey.github.io/p/dell-precision-t1700-sff/","title":"DELL Precision T1700 SFF"},{"content":"又是关于 MySQL 的, 标题来自于 \u0026lt;轮到你了\u0026gt; 这部烂尾日剧, 里面非常魔性的 Oh~my~Ju~lia~\n在MySQL里面如何保存 Emoji, 这个问题搜一搜很容易找到答案, 设置 CHARSET 为 utf8mb4, 看来天下苦 MySQL 久矣.\n基础知识 计算机最早是美国人发明的, 那时的编码都是 ASCII 码, 毕竟英文字符加上标点符号也就那么多嘛, 一个字节绰绰有余.\n但是随着计算机的发展, 计算机面向的国家和语言越来越多, 一个字节根本不够用了, 于是就有了很多面向特定语言的编码, 比如汉字的GBK, Big5, 韩文的 EUC-KR, 日文的 Shift_JIS 什么的. 总体思想是, 既然一个字节不够用, 那就多几个字节就是了嘛.\n但是问题又出现了, 同一个编码在不同语言中会有不同的含义,比如韩文编码 EUC-KR 中 한국어 的编码值正好对应着汉字编码 GBK 中的 茄惫绢. 还有那个著名的 瓣B变巨肚, 也正是同样的原因. 这样仿佛就变成了巴别塔的故事. 人们虽然用着同样的二进制编码, 但是却表达着不同的意思; 就像人们虽然同样发出声带的震动, 但是却无法互相理解对方的话语.\n国际标准化组织 和 统一码联盟 意识到, 这样下去是不行的, 不如搞一个超大的字符集, 然后把人类所有字符都弄进去, 这样人类都可以用同一个标准了. 于是, 他们分别制定了 USC 和 Unicode. 当然, 如果两个标准各搞各的, 那就和他们最初的想法背道而驰了, 所以目前这两个字符集在实际使用中是一致的. 一般还是把这个字符集叫 Unicode.\nUnicode 的范围上限是 0x10FFFF, 换算成十进制就是 1,114,111 这么多. 所以如果以后外星人的文字太多, 说不定这个范围就不够了.\n其实这里悄悄的偷换了一个概念, 之前在说编码, 现在变成了字符集了. 在很多之前提到的编码中, 这些编码既是字符集, 又是直接的编码. 而在 Unicode 中, 字符集实际上是与编码分开的两个概念, 而对应的编码, 实际上就是我们经常见到的 UTF. 其中 UTF-8 是我们最常见的一种编码了.\nUTF-8 最大的特点, 就是它是一种变长的编码方式, 而且完全兼容 ASCII码.\nUTF-8 的编码规则也很简单，只有二条:\n对于单字节的符号, 字节的第一位设为0, 后面7位为这个符号的 Unicode 码. 对于 0 - 127 位的字符，UTF-8 编码和 ASCII 码是完全相同的.\n对于 n 字节的符号 (n \u0026gt; 1) , 第一个字节的前 n 位都设为 1, 第 n + 1 位设为 0, 后面字节的前两位一律设为 10. 剩下的没有提及的二进制位, 全部为这个符号的 Unicode 码.\nUnicode符号范围 UTF-8编码方式 U+0000 - U+007F 0xxxxxxx U+0080 - U+07FF 110xxxxx 10xxxxxx U+0800 - U+FFFF 1110xxxx 10xxxxxx 10xxxxxx U+010000 - U+10FFFF 11110xxx 10xxxxxx 10xxxxxx 10xxxxxx 在这里我们发现, U+0000 - U+FFFF 这个平面(Plane), 即基本多文种平面, 简称 BMP, 用 UTF-8 进行编码, 只需要三个字节.\n轮到你了 在 MySQL 的 CHARSET 中, utf8 支持存储 1 - 3字节的字符, 即对应 Unicode 中 BMP 的部分, 而 Emoji, 则大多数在 BMP 之外. 所以 MySQL 中的 utf8 是假的, 是化学的成分, 是加了特技的. 如果想储存真正的 UTF-8 的内容, 就一定要使用 utf8mb4.\n当然, 并不是所有的 Emoji 都在 BMP 之外, 比如 ☺ 这个表情, 它的编码是 U+263A, 还有 ☹️ , 编码是 U+2639.\n当然, 也不是所有的汉字都被包含在了 BMP 里面了, 在 这里 可以看到字符是按照一定的规律划分为 Block 放进来的, 在表意文字补充平面也就是 U+20000 - U+2FFFF 这个平面(Plane), 还是有很多 CJK 命名的 Block 的.\n再来一瓶 你以为坑到这里就结束了吗\n1 2 3 4 5 CREATE TABLE `emoji_test` ( `id` INT UNSIGNED NOT NULL AUTO_INCREMENT, `emoji` VARCHAR(1024) NOT NULL, PRIMARY KEY (`id`) ) ENGINE=InnoDB DEFAULT CHARSET=utf8mb4; 1 SET NAMES utf8mb4; 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 MySQL [test]\u0026gt; SELECT * FROM emoji_test; +----+-------+ | id | emoji | +----+-------+ | 8 | 😃 | | 9 | 😂 | | 10 | 🤦 | +----+-------+ 3 rows in set (0.001 sec) MySQL [test]\u0026gt; SELECT * FROM emoji_test WHERE emoji = \u0026#39;😂\u0026#39;; +----+-------+ | id | emoji | +----+-------+ | 8 | 😃 | | 9 | 😂 | | 10 | 🤦 | +----+-------+ 3 rows in set (0.001 sec) 是不是很神奇呢, 看下表的信息呢\n1 2 3 4 5 6 7 MySQL [test]\u0026gt; SHOW TABLE STATUS WHERE Name = \u0026#39;emoji_test\u0026#39;; +------------+--------+---------+------------+------+----------------+-------------+-----------------+--------------+-----------+----------------+---------------------+---------------------+------------+--------------------+----------+----------------+---------+ | Name | Engine | Version | Row_format | Rows | Avg_row_length | Data_length | Max_data_length | Index_length | Data_free | Auto_increment | Create_time | Update_time | Check_time | Collation | Checksum | Create_options | Comment | +------------+--------+---------+------------+------+----------------+-------------+-----------------+--------------+-----------+----------------+---------------------+---------------------+------------+--------------------+----------+----------------+---------+ | emoji_test | InnoDB | 10 | Dynamic | 3 | 5461 | 16384 | 0 | 0 | 0 | 11 | 2019-10-16 11:16:28 | 2019-10-16 11:25:10 | NULL | utf8mb4_general_ci | NULL | | | +------------+--------+---------+------------+------+----------------+-------------+-----------------+--------------+-----------+----------------+---------------------+---------------------+------------+--------------------+----------+----------------+---------+ 1 row in set (0.001 sec) 可以看到此时默认的字符序是 utf8mb4_general_ci, 使用 WEIGHT_STRING 来查询这些 Emoji 的字符序\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 MySQL [test]\u0026gt; SET @s = \u0026#39;😂\u0026#39; COLLATE utf8mb4_general_ci; Query OK, 0 rows affected (0.003 sec) MySQL [test]\u0026gt; SELECT @s, HEX(@s), HEX(WEIGHT_STRING(@s)); +------+----------+------------------------+ | @s | HEX(@s) | HEX(WEIGHT_STRING(@s)) | +------+----------+------------------------+ | 😂 | F09F9882 | FFFD | +------+----------+------------------------+ 1 row in set (0.001 sec) MySQL [test]\u0026gt; SET @s = \u0026#39;😃\u0026#39; COLLATE utf8mb4_general_ci; Query OK, 0 rows affected (0.001 sec) MySQL [test]\u0026gt; SELECT @s, HEX(@s), HEX(WEIGHT_STRING(@s)); +------+----------+------------------------+ | @s | HEX(@s) | HEX(WEIGHT_STRING(@s)) | +------+----------+------------------------+ | 😃 | F09F9883 | FFFD | +------+----------+------------------------+ 1 row in set (0.001 sec) 可以看到, 它们的编码虽然不同, 但是字符序的值是相同的, 都是 0xFFFD, 所以在匹配的时候, 它们被认为是同一个字符, 这又是 MySQL 的一个大坑\n要是想粗暴点解决问题的话, 直接使用 utf8mb4_bin 作为字符序就好了\n又来一瓶 但是这还不是结束, 当业务代码连接数据库并插入一些 Emoji 时, 还是可能遇到如下错误\n1 ERROR 1366: Incorrect string value: \u0026#39;\\xF0\\x9D\\x8C\\x86\u0026#39; for column \u0026#39;column_name\u0026#39; at row 1 这个是因为客户端到 MySQL 服务器的连接还是 utf8 而非 utf8mb4, 所以你需要在业务逻辑中做类似如下语句的事情\n1 SET NAMES utf8mb4 或者修改 MySQL 的配置文件, 当然这样不太现实, 需要重启 MySQL 进程.\n这样你才能终于用上 Emoji\n参考资料 How can I search by emoji in MySQL using utf8mb4? 字符编码笔记：ASCII，Unicode 和 UTF-8 如何通俗地理解Unicode、UTF-8、ASCII、GBK等字符编码？ In MySQL, never use “utf8”. Use “utf8mb4”. How to support full Unicode in MySQL databases Connection Character Sets and Collations “Incorrect string value” when trying to insert UTF-8 into MySQL via JDBC? 扩展阅读 其实你并不懂 Unicode Dark corners of Unicode MySQL · 实现分析 · 对字符集和字符序支持的实现 unicodedata — Unicode Database ","date":"2019-10-14T11:12:33+08:00","permalink":"https://memwey.github.io/p/oh-mysql-emoji/","title":"Oh MySQL Emoji"},{"content":"感觉 MySQL 的坑实在是有点多,记录一下这个 MySQL 的坑, 也记录一下这个教训吧, 下次在数据库中直接操作一定要多小心\n现象回放 现在有两张表, 表结构如下, 无关字段已经省略\nteam 1 2 3 4 5 6 +-------------+---------------------+ | Field | Type | +-------------+---------------------+ | id | int(10) unsigned | | status | tinyint(3) unsigned | +-------------+---------------------+ player 1 2 3 4 5 6 7 +-------------+---------------------+ | Field | Type | +-------------+---------------------+ | id | int(10) unsigned | | team_id | int(10) unsigned | | status | tinyint(3) unsigned | +-------------+---------------------+ 容易理解, 这是简单的一对多的关系, 一个足球队 team 里面, 有多个球员 player\n现在想取出有 player 的状态为 1 的 team\n1 SELECT * FROM team WHERE id IN (SELECT id FROM (SELECT team_id FROM player WHERE status = 1) AS a); 理论上, 这条语句是不能执行的, 注意这里\n\u0026hellip;\u0026hellip; SELECT id FROM (SELECT team_id FROM \u0026hellip;\u0026hellip;\n但是, 不知道为何, 这条语句是可以执行的, 而且等价于\n1 SELECT * FROM team; 如果单独把最外层的 IN 里面的 subquery 取出来, MySQL 会报错\n1 SELECT id FROM (SELECT team_id FROM player WHERE status = 1) AS a; ERROR 1054 (42S22): Unknown column \u0026lsquo;id\u0026rsquo; in \u0026lsquo;field list\u0026rsquo;\n再试着把 id 改为不存在的字段\n1 SELECT * FROM team WHERE id IN (SELECT not_exist_field FROM (SELECT team_id FROM player WHERE status = 1) AS a); ERROR 1054 (42S22): Unknown column \u0026rsquo;not_exist_field\u0026rsquo; in \u0026lsquo;field list\u0026rsquo;\n这样才能如预期的报错\n问题排查 先 EXPLAIN 试试呢\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 *************************** 1. row *************************** id: 1 select_type: SIMPLE table: team partitions: NULL type: ALL possible_keys: NULL key: NULL key_len: NULL ref: NULL rows: 2 filtered: 100.00 Extra: NULL *************************** 2. row *************************** id: 1 select_type: SIMPLE table: player partitions: NULL type: ALL possible_keys: NULL key: NULL key_len: NULL ref: NULL rows: 5 filtered: 20.00 Extra: Using where; FirstMatch(team); Using join buffer (Block Nested Loop) 2 rows in set, 2 warnings (0.001 sec) 好像看不出来什么问题呢, 不过有 warnings, 看一下呢\n1 SHOW WARNINGS\\G 1 2 3 4 5 6 7 8 9 *************************** 1. row *************************** Level: Note Code: 1276 Message: Field or reference \u0026#39;test.team.id\u0026#39; of SELECT #2 was resolved in SELECT #1 *************************** 2. row *************************** Level: Note Code: 1003 Message: /* select#1 */ select `test`.`team`.`id` AS `id`,`test`.`team`.`status` AS `status` from `test`.`team` semi join (`test`.`player`) where (`test`.`player`.`status` = 1) 2 rows in set (0.001 sec) 这里出现了一个 semi join, 没有见过呢, 查看一下文档, 大意就是, 比如使用 INNER JOIN 的时候, 会返回匹配次数个结果. 但是我们并不关注匹配的次数, 比如如下语句, 我想取出有球员的 status 为 0 的球队, 可以这样写\n1 SELECT * FROM team INNER JOIN player ON team.id = team_id WHERE player.status = 0; 如果一个球队里有多个 status 为 0 的球员, 那么就会出现多个记录, 比如这样\n1 2 3 4 5 6 7 8 +----+--------+----+---------+--------+ | id | status | id | team_id | status | +----+--------+----+---------+--------+ | 1 | 0 | 1 | 1 | 0 | | 1 | 0 | 2 | 1 | 0 | | 2 | 0 | 5 | 2 | 0 | | 2 | 0 | 6 | 2 | 0 | +----+--------+----+---------+--------+ 这样明显有些冗余的数据了. 当然我们可以用 DISTINCT 什么的再处理一遍, 但是这样效率会比较低. 那么, 就可以用类似的子查询就方便多了\n1 SELECT * FROM team WHERE id IN (SELECT team_id FROM player WHERE status = 0); 返回的结果也简洁多了\n1 2 3 4 5 6 +----+--------+ | id | status | +----+--------+ | 1 | 0 | | 2 | 0 | +----+--------+ 当然, 要这样优化还是有很多条件的, 林林总总的, 可以去官方文档查看\n看了这么多, 感觉还是和这个问题没什么关系啊, 试着 EXPLAIN 一下正确的语句\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 *************************** 1. row *************************** id: 1 select_type: SIMPLE table: team partitions: NULL type: ALL possible_keys: PRIMARY key: NULL key_len: NULL ref: NULL rows: 2 filtered: 100.00 Extra: NULL *************************** 2. row *************************** id: 1 select_type: SIMPLE table: player partitions: NULL type: ALL possible_keys: NULL key: NULL key_len: NULL ref: NULL rows: 5 filtered: 20.00 Extra: Using where; FirstMatch(team); Using join buffer (Block Nested Loop) 2 rows in set, 1 warning (0.001 sec) 再看看 warnings\n1 2 3 4 5 *************************** 1. row *************************** Level: Note Code: 1003 Message: /* select#1 */ select `test`.`team`.`id` AS `id`,`test`.`team`.`status` AS `status` from `test`.`team` semi join (`test`.`player`) where ((`test`.`player`.`team_id` = `test`.`team`.`id`) and (`test`.`player`.`status` = 1)) 1 row in set (0.001 sec) 对照着实际运行的语句的 Note, 发现错误的语句缺少了以下这个条件\n((test.player.team_id = test.team.id)\n难道就是你! 但是为什么又有\nField or reference \u0026rsquo;test.team.id\u0026rsquo; of SELECT #2 was resolved in SELECT #1\n这个问题呢\n总感觉是个Bug\u0026hellip;\u0026hellip;\nTo Be Continued\u0026hellip;\u0026hellip;\n参考资料 Optimizing Subqueries, Derived Tables, and View References with Semijoin Transformations ","date":"2019-09-21T15:22:58+08:00","permalink":"https://memwey.github.io/p/oh-mysql-in-subquery/","title":"Oh MySQL IN Subquery"},{"content":"最近看到一个有趣的 GNU/Linux 命令, yes\n先 man 一下\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 YES(1) BSD General Commands Manual YES(1) NAME yes -- be repetitively affirmative SYNOPSIS yes [expletive] DESCRIPTION yes outputs expletive, or, by default, ``y\u0026#39;\u0026#39;, forever. HISTORY The yes command appeared in 4.0BSD. 4th Berkeley Distribution June 6, 1993 4th Berkeley Distribution (END) emmmmm, 在 macOS 下并没有 --help 或者 -h 的选项\n试试 Linux 下呢\n1 2 3 4 5 6 7 8 9 10 11 ➜ / yes --help Usage: yes [STRING]... or: yes OPTION Repeatedly output a line with all specified STRING(s), or \u0026#39;y\u0026#39;. --help display this help and exit --version output version information and exit GNU coreutils online help: \u0026lt;https://www.gnu.org/software/coreutils/\u0026gt; Full documentation at: \u0026lt;https://www.gnu.org/software/coreutils/yes\u0026gt; or available locally via: info \u0026#39;(coreutils) yes invocation\u0026#39; 有了\n简单来说这个命令就是可以反复的输出一个字符串, 这个字符串的默认值是 y\n于是有了一些特别的用法, 比如, 注意这里没有 f\n1 yes | rm -r / 还有\n1 yes $(yes yes) 好孩子不要乱试\n当然这个命令的效果其实一般都有替代, 比如加上 -f, -y 什么的, 生成一个大文件也可以用 /dev/urandom 来做\n还可以在冬天做暖手宝, 噗\n最后, 跟我一起在命令行输入\n1 yes \u0026#39;AMD, yes!\u0026#39; 果然人类的本质就是复读机\n","date":"2018-12-14T23:34:15+08:00","permalink":"https://memwey.github.io/p/yes/","title":"Yes"},{"content":"新的博客, 重新开始\n这次尝试着坚持一下吧\n","date":"2018-09-17T23:26:20+08:00","permalink":"https://memwey.github.io/p/%E9%87%8D%E6%96%B0%E5%BC%80%E5%A7%8B/","title":"重新开始"},{"content":"最近研究了一下红黑树的一些性质和思想, 在这里记录一下.\nMap, 或者在 Python 等一些语言中叫做 dictionary 的常用的以键值对形式储存的数据结构一般有两种实现方式, 在 C++ 的 STL 中使用了红黑树的方式, 而在Python中使用了哈希表的方式.\n一般认为采用哈希表的方式查找删除的时间复杂度为 O(1), 而红黑树为 O(logn).\nPython 中的哈希表使用开放寻址法解决冲突.\n对于普通的二叉查找树来说, 查找和插入的时间复杂度在最坏的情况下可能会变成 O(n), 即完全偏向一边的不平衡情况使其成为一个单链表. 如果只是在树的叶子上增加节点而不进行其他的调整, 很容易会使只向下增长的树不平衡. 为了保证 O(logn) 的时间复杂度, 我们需要一种动态的机制, 来调整树的父节点, 乃至于根节点.\n红黑树是一种动态调整的实现方式. 红黑树其实是在 2, 3-树 的基础上实现的. 他们也完全可以等价的转换. 不过 2, 3-树 在程序的实现上比较复杂, 而且查找操作也和二叉搜索树有一些不同, 所以在程序实现中一般使用红黑树.\n2, 3-树 和红黑树他们共同的思想是, 将树的叶子节点上的操作造成的影响, 逐步的传递给父节点, 按照一定的方式对当前子树进行调整. 父节点再传递给它的父节点, 调整更大一些的子树. 最终传递到根节点, 调整整颗树.\n可以这样理解, 在红黑树中, 用红色来标记正在累计调整的节点. 当节点M的两个子节点均被标记, 则M取消子节点的标记, 并标记自己, 使调整向根节点传递.\n","date":"2016-09-13T23:32:27+08:00","permalink":"https://memwey.github.io/p/%E7%BA%A2%E9%BB%91%E6%A0%91%E7%AC%94%E8%AE%B0/","title":"红黑树笔记"},{"content":"公司的服务器都是 CentOS 的, 带的软件都比较旧, 让我这个不更新会死星人很难过啊.\n开玩笑的, 主要问题是 git 版本太旧, clone 的时候会报错, 然后也需要 python3.5. 在 git 上面发现 ius 来解决这个问题.\nius 是一个社区项目, 目的是为 Linux 的企业发行版提供一些更新版本的RPM包.\n1 2 sudo yum install epel-release sudo yum install https://centos6.iuscommunity.org/ius-release.rpm 为了解决一些冲突和共存的问题, 有一些 package 在 ius 中的包名有一些改动\n1 2 sudo yum install git2u sudo yum install python35u 一般的命名规则是\n{name}{major_version}{minor_version}u\n这样就可以在 CentOS 上使用较新的软件啦.\n","date":"2016-08-02T23:30:33+08:00","permalink":"https://memwey.github.io/p/%E5%9C%A8centos%E4%B8%8A%E4%BD%BF%E7%94%A8%E8%BE%83%E6%96%B0%E7%9A%84%E8%BD%AF%E4%BB%B6/","title":"在CentOS上使用较新的软件"},{"content":"最近在跑 DHT 网络拟真的时候涉及到一些 linux 后台运行的一些东西,现在总结一下\n例如\n1 nohup ../src/OverSim -c ChordChurn -u Cmdenv \u0026gt; out.file 2\u0026gt;\u0026amp;1 \u0026amp; 使得 ../src/OverSim -c ChordChurn -u Cmdenv 命令在后台运行,并将 stderr 重定向到 stdout 中然后再将 stdout 重定向到 out.file, 并且在当前终端关闭时仍然运行\n具体说一下吧\nnohup 退出终端的时候,一般在终端中运行的进程会随之关闭,因为此时终端中的子进程会收到 SIGHUP 信号. 而 nohup 使得进程忽略所有 SIGHUP 信号. stdout 默认会重定向到 nohup.out 文件中\n\u0026amp; 在命令中末尾加入 \u0026amp; 符号,使进程在后台运行\n2\u0026gt;\u0026amp;1 放在 \u0026gt; 后面的 \u0026amp;, 表示重定向的目标不是一个文件, 而是一个文件描述符, 文件描述符\n1 =\u0026gt; stdout 2 =\u0026gt; stderr 0 =\u0026gt; stdin 其他一些命令和操作 Control+z 可以发出 SIGSTOP 信号, 使当前前台进程暂停并放入后台\nfg [job_id]使进程在前台运行\nbg [job_id]使进程在后台运行\njobs 查看后台进程\n","date":"2016-06-15T23:28:24+08:00","permalink":"https://memwey.github.io/p/linux%E5%90%8E%E5%8F%B0%E5%91%BD%E4%BB%A4/","title":"Linux后台命令"},{"content":"其实很早就想弄个博客什么的, 觉得有些东西费了很大的力气解决了, 然后久而久之就忘了\u0026hellip;\u0026hellip;记录下来应该会好一点吧, 这样觉得.\n所以还是写一些东西吧, 嗯嗯\u0026hellip;\u0026hellip;\n其实还是不太喜欢这种不怎么能自己定制的东西\u0026hellip;\u0026hellip;总有一种不知所措的感觉\u0026hellip;\u0026hellip;自己写一个后台倒是没什么问题, 前端的话就实在是无力了, 噗\n对 Markdown 的语法还不那么熟悉, 而且好像 Markdown 有一些不同的解释器, 很麻烦啊\n每次生成的静态网页还要在本地生成了之后看过效果\u0026hellip;\u0026hellip;啊, 真的很麻烦\n","date":"2016-06-14T23:22:32+08:00","permalink":"https://memwey.github.io/p/%E7%AC%AC%E4%B8%80%E7%AF%87%E5%8D%9A%E5%AE%A2/","title":"第一篇博客"}]